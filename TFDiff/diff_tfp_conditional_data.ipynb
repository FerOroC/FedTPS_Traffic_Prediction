{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a68efcae-136d-41db-907c-ebadd251a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c83b2-d7ac-49c1-8db8-de03123fefd8",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30840d-b439-4aaf-817b-7f1b84b4c78b",
   "metadata": {},
   "source": [
    "lets make conditional data represent [time interval of day, day of week, mean traffic vol, max traffic vol, grid cell with max traffic vol, weather]\n",
    "\n",
    "expand to weather  \n",
    "holiday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b3190818-e25a-49af-93ee-5bff614cec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def fetch_and_encode_weather_data(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch and encode weather data into 30-minute intervals with one-hot encoding for weather categories.\n",
    "\n",
    "    Parameters:\n",
    "    - latitude (float): Latitude of the location.\n",
    "    - longitude (float): Longitude of the location.\n",
    "    - start_date (str): Start date in YYYY-MM-DD format.\n",
    "    - end_date (str): End date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Encoded weather data as a DataFrame.\n",
    "    \"\"\"\n",
    "    base_url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "\n",
    "    # Generate list of dates for the range\n",
    "    start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    date_list = [(start + datetime.timedelta(days=i)).strftime(\"%Y-%m-%d\") for i in range((end - start).days + 1)]\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for date in date_list:\n",
    "        # Build API request\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": date,\n",
    "            \"end_date\": date,\n",
    "            \"hourly\": \"precipitation,sunshine_duration,weather_code\",\n",
    "            \"timezone\": \"Asia/Shanghai\"\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        # Extract hourly data\n",
    "        hourly_data = data.get(\"hourly\", {})\n",
    "        for i, timestamp in enumerate(hourly_data.get(\"time\", [])):\n",
    "            condition = \"cloudy\"  # Default condition\n",
    "\n",
    "            # Define weather conditions based on precipitation and temperature\n",
    "            precipitation = hourly_data.get(\"precipitation\", [0])[i]\n",
    "            sunshine_duration =  hourly_data.get(\"sunshine_duration\", [0])[i]\n",
    "            weather_code = hourly_data.get(\"weather_code\", [0])[i]\n",
    "\n",
    "            if (precipitation > 0) & (weather_code < 60 | weather_code > 50):  # rain\n",
    "                encoding = 2\n",
    "            elif sunshine_duration < 1000:  # cloudy\n",
    "                encoding = 1\n",
    "            elif sunshine_duration > 1000:  # sunny \n",
    "                encoding = 0 \n",
    "\n",
    "            all_data.append({\n",
    "                \"timestamp\": timestamp,\n",
    "                \"sunshine_duration\": sunshine_duration,\n",
    "                \"precipitation\": precipitation,\n",
    "                \"weather_code\": weather_code,\n",
    "                \"encoding\": encoding\n",
    "            })\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "\n",
    "    # Resample to 30-minute intervals (assuming input is hourly)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "    df = df.set_index(\"timestamp\").resample(\"30T\").asfreq().fillna(method=\"ffill\").reset_index()\n",
    "\n",
    "    # Add final row\n",
    "    encoded_array = df['encoding'].copy()\n",
    "    encoded_array[len(encoded_array)] = df['encoding'].iloc[-1]\n",
    "    \n",
    "    return encoded_array\n",
    "\n",
    "# Example usage\n",
    "LATITUDE = 30.5728  # Latitude of Chengdu, China\n",
    "LONGITUDE = 104.0668  # Longitude of Chengdu, China\n",
    "START_DATE = \"2016-11-01\"\n",
    "END_DATE = \"2016-11-30\"\n",
    "\n",
    "weather_data = fetch_and_encode_weather_data(LATITUDE, LONGITUDE, START_DATE, END_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "842cb817-705e-4de7-b58e-a4954dc9977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_data_from_inflow(inflow_data):\n",
    "    \n",
    "    def z_score_normalisation_main_data(data):\n",
    "        # Check if the input shape matches the expected format (x, 1440, 100)\n",
    "        if data.shape[2] != 100:\n",
    "            raise ValueError(\"Input data must have shape (x, 1440, 100), where x can vary.\")\n",
    "    \n",
    "        # Compute mean and standard deviation for the entire dataset\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "    \n",
    "        # Avoid division by zero by replacing zero std values with a small number\n",
    "        if std == 0:\n",
    "            std = 1e-8\n",
    "    \n",
    "        # Apply z-score normalization to the entire dataset\n",
    "        normalized_data = (data - mean) / std\n",
    "    \n",
    "        return normalized_data, mean, std\n",
    "\n",
    "    \n",
    "    def z_score_normalisation_head_data(data):\n",
    "        # Check if the input shape matches the expected format (x, 1440, 5)\n",
    "    \n",
    "        # Extract the second last feature (index 2,3)\n",
    "        feature_data = data[:, :, 2:3]\n",
    "    \n",
    "        # Compute mean and standard deviation for the selected feature across the entire dataset\n",
    "        mean = np.mean(feature_data)\n",
    "        std = np.std(feature_data)\n",
    "    \n",
    "        # Avoid division by zero by replacing zero std values with a small number\n",
    "        if std == 0:\n",
    "            std = 1e-8\n",
    "    \n",
    "        # Apply z-score normalization only to the selected feature\n",
    "        normalized_feature = (feature_data - mean) / std\n",
    "    \n",
    "        # Create a copy of the original data and replace the normalized feature\n",
    "        normalized_data = data.copy()\n",
    "        normalized_data[:, :, 2:3] = normalized_feature\n",
    "\n",
    "        mean = np.mean(data, axis=(0, 1))  # Mean for each feature (length 4)\n",
    "        std = np.std(data, axis=(0, 1))    # Std for each feature (length 4)\n",
    "\n",
    "        mean[0:2] = 0\n",
    "        mean[3:] = 0\n",
    "        std[0:2] = 1\n",
    "        std[3:] = 1\n",
    "    \n",
    "        return normalized_data, mean, std\n",
    "    \n",
    "    \n",
    "    # conditional data represent [time interval of day, day of week, max traffic vol, grid cell with max traffic vol]\n",
    "    conditional_data = np.zeros((inflow_data.shape[0],inflow_data.shape[1],4))\n",
    "\n",
    "    for client in range(inflow_data.shape[0]):\n",
    "        for i in range(1440):\n",
    "            # time interval of day\n",
    "            conditional_data[client,i,0] = (i%48)\n",
    "            # day of week, first day is Tuesday\n",
    "            conditional_data[client,i,1] = ((1 + (i // 48))%7)\n",
    "            # # mean traffic vol\n",
    "            # conditional_data[client,i,2] = np.mean(inflow_data[client,i])\n",
    "            # max traffic vol\n",
    "            conditional_data[client,i,2] = np.max(inflow_data[client,i])\n",
    "            # grid cell with max traffic vol\n",
    "            conditional_data[client,i,3] = np.argmax(inflow_data[client,i])\n",
    "            # # weather data\n",
    "            # conditional_data[client,i,5] = weather_data[i] \n",
    "\n",
    "    normalised_conditional_data, mean_conditional_data, std_conditional_data = z_score_normalisation_head_data(conditional_data)\n",
    "    normalised_main_data, mean_main_data, std_main_data = z_score_normalisation = z_score_normalisation_main_data(inflow_data)\n",
    "    \n",
    "    return conditional_data, normalised_conditional_data, mean_conditional_data, std_conditional_data,\\\n",
    "    inflow_data, normalised_main_data, mean_main_data, std_main_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0729645-9c25-4095-bfda-235a854aeaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(num_clients,city, normalised_main_data,normalised_conditional_data,extra_data):\n",
    "    np.save(f\"data/{city}/{num_clients}_client/inflow_main.npy\", normalised_main_data[..., np.newaxis])\n",
    "    np.save(f\"data/{city}/{num_clients}_client/inflow_conditional.npy\", normalised_conditional_data)\n",
    "    np.save(f\"data/{city}/{num_clients}_client/extra_data.npy\", extra_data)\n",
    "\n",
    "def data_processing(num_clients, city):\n",
    "    inflow_data = np.load(f\"data/{city}/{num_clients}_client/inflow_main.npy\")\n",
    "    conditional_data, normalised_conditional_data, mean_conditional_data,\\\n",
    "    std_conditional_data, inflow_data, normalised_main_data, mean_main_data, std_main_data = conditional_data_from_inflow(inflow_data) \n",
    "\n",
    "    extra_data = {\n",
    "    'mean conditional data':[mean_conditional_data],\n",
    "    'std conditional data':[std_conditional_data],\n",
    "    'mean main data':[mean_main_data],\n",
    "    'std main data':[std_main_data],\n",
    "    }\n",
    "    print(extra_data)\n",
    "    save_data(num_clients,city,normalised_main_data,normalised_conditional_data,extra_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
